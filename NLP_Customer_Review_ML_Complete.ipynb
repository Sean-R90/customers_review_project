{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - Customer Review ML Complete ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOTtuC/C9H6d1xtSIKNd+Vw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasmoratof/customers_review_project/blob/master/NLP_Customer_Review_ML_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR-woI-YoNGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAB-SITcoXso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = pd.read_csv('https://raw.githubusercontent.com/lucasmoratof/customers_review_project/master/reviews_for_nlp.csv', usecols=['review_comment_message', 'is_good_review'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4vAgfRdocYO",
        "colab_type": "code",
        "outputId": "3ee5b1c0-1f9b-4d19-bed2-3faa1e3c2aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_comment_message</th>\n",
              "      <th>is_good_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              review_comment_message  is_good_review\n",
              "0              Recebi bem antes do prazo estipulado.               1\n",
              "1  Parabéns lojas lannister adorei comprar pela I...               1\n",
              "2  aparelho eficiente. no site a marca do aparelh...               1\n",
              "3      Mas um pouco ,travando...pelo valor ta Boa.\\n               1\n",
              "4  Vendedor confiável, produto ok e entrega antes...               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eBnik4J3hsv",
        "colab_type": "text"
      },
      "source": [
        "I will try some techniques to count the number of characters and words in each review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DvIagii3SeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count the lenght of each review\n",
        "reviews['char_count'] = reviews['review_comment_message'].apply(len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGazaA8d4DFZ",
        "colab_type": "code",
        "outputId": "6d60667d-fc1a-4e81-dc0d-4d5cffb1f866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "reviews['char_count'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     37\n",
              "1    100\n",
              "2    174\n",
              "3     44\n",
              "4     56\n",
              "Name: char_count, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj-B5HtM4Fzz",
        "colab_type": "code",
        "outputId": "fd7bbcf3-d679-4047-d4ce-dee61f4b8be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# average characters in the reviews\n",
        "reviews['char_count'].mean() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.82382526225032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpsOXx714bP_",
        "colab_type": "code",
        "outputId": "6ca99d44-082c-4cb7-8783-e729ca2a242c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# create a function to count the number of words in each comment\n",
        "def count_words(string):\n",
        "  words = string.split()\n",
        "  return len(words)\n",
        "\n",
        "# applying the funciton to create a new feature\n",
        "reviews['word_count'] = reviews['review_comment_message'].apply(count_words)\n",
        "\n",
        "# finding the average number of words in the reviews\n",
        "print(reviews['word_count'].mean()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.901374718589835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P_0660z_lKf",
        "colab_type": "text"
      },
      "source": [
        "Some text preprocessing techiniques:\n",
        "\n",
        "- Convert words into lowercase\n",
        "- Removing leading and trailing whitespaces\n",
        "- Removing punctuation\n",
        "- Removing stopwords\n",
        "- Expanding contractions\n",
        "- Removing special characters (numbers, emojis, etc)\n",
        "\n",
        "**Tokenization** is the process of converting words into a numerical format, called token. We can also convert sentences and ponctuation into tokens.\n",
        "\n",
        "**Lemmatization** is the process of converting word into it's lowercase base form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsc03Yd4AuxK",
        "colab_type": "code",
        "outputId": "caf81e12-8ba4-4ad2-eaeb-e68c4bf821eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# If you need to download the model (works on google colab)\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"pt_core_news_sm\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AE-Ieu8_97N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Portuguese model\n",
        "import spacy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4WTPiJfA3KP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc= nlp(reviews['review_comment_message'][2])\n",
        "# IMPORTANT, when you pass the strings through nlp(), it performs Lemmatization by default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdRq_iuACtDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = [token.text for token in doc]\n",
        "lemmas= [token.lemma_ for token in doc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etQEoE9hFfOu",
        "colab_type": "code",
        "outputId": "cf9c7a37-f96f-43c5-9516-fd6b0db613b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(tokens, \"\\n\", lemmas)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aparelho', 'eficiente', '.', 'no', 'site', 'a', 'marca', 'do', 'aparelho', 'esta', 'impresso', 'como', '3desinfector', 'e', 'a', 'o', 'chegar', 'esta', 'com', 'outro', 'nome', '...', 'atualizar', 'com', 'a', 'marca', 'correta', 'uma', 'vez', 'que', 'é', 'o', 'mesmo', 'aparelho'] \n",
            " ['aparelhar', 'eficiente', '.', 'o', 'site', 'o', 'marcar', 'do', 'aparelhar', 'este', 'impresso', 'comer', '3desinfector', 'e', 'o', 'o', 'chegar', 'este', 'com', 'outro', 'nome', '...', 'atualizar', 'com', 'o', 'marcar', 'corretar', 'umar', 'vez', 'que', 'ser', 'o', 'mesmo', 'aparelhar']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lExguy8BFjD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stopwords\n",
        "stopwords = spacy.lang.pt.stop_words.STOP_WORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrJp0jwNG_Dj",
        "colab_type": "code",
        "outputId": "07028041-da87-41c6-bed7-37f9f7ad9047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "no_stops= [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords]\n",
        "print(' '.join(no_stops))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aparelhar eficiente o site o marcar aparelhar impresso comer e o o chegar outro nome atualizar o marcar corretar umar o aparelhar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rr0qCFGHVvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a function that combines tokenization and lemmatization\n",
        "\n",
        "def preprocessing(text):\n",
        "  doc= nlp(text) # creates the document\n",
        "  lemmas= [token.lemma_ for doc in doc] # extracts the lemmas\n",
        "  # time to remove stopwords (remember that we are using the Portuguese version)\n",
        "  clean_lemmas= [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords]\n",
        "\n",
        "  return ' '.join(clean_lemmas) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L6VC_C1hlO7",
        "colab_type": "text"
      },
      "source": [
        "Part of Speech - POS\n",
        "It determines the meaning of each word, like proper noun, verb, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ai4YBpniKat",
        "colab_type": "code",
        "outputId": "edb1bb62-8bb7-4796-a8ed-55a009fcc5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# load the model\n",
        "nlp= spacy.load('pt_core_news_sm')\n",
        "\n",
        "# create the doc\n",
        "doc= nlp(reviews['review_comment_message'][2])\n",
        "\n",
        "# generate tokens and pos tags\n",
        "pos= [(token.text, token.pos_) for token in doc]\n",
        "print(pos)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('aparelho', 'NOUN'), ('eficiente', 'ADJ'), ('.', 'PUNCT'), ('no', 'ADP'), ('site', 'VERB'), ('a', 'DET'), ('marca', 'NOUN'), ('do', 'DET'), ('aparelho', 'NOUN'), ('esta', 'DET'), ('impresso', 'VERB'), ('como', 'ADP'), ('3desinfector', 'NUM'), ('e', 'PUNCT'), ('a', 'ADP'), ('o', 'DET'), ('chegar', 'VERB'), ('esta', 'DET'), ('com', 'ADP'), ('outro', 'DET'), ('nome', 'NOUN'), ('...', 'PUNCT'), ('atualizar', 'VERB'), ('com', 'ADP'), ('a', 'DET'), ('marca', 'NOUN'), ('correta', 'ADJ'), ('uma', 'DET'), ('vez', 'NOUN'), ('que', 'SCONJ'), ('é', 'VERB'), ('o', 'DET'), ('mesmo', 'DET'), ('aparelho', 'NOUN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-c5T_KXjHMh",
        "colab_type": "text"
      },
      "source": [
        "Below I will create to functions, to count the number of proper nouns and nouns, then, I will apply these function on the data separating good reviews and bad reviews. Finally, I will calculate the mean of PROPN and NOUNS on both groups and compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97mLDuWnl9Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PROPN\n",
        "def proper_nouns(text, model=nlp):\n",
        "  # Create doc object\n",
        "  doc= model(text)\n",
        "  # Generate list of POS tags\n",
        "  pos= [token.pos_ for token in doc]\n",
        "  return pos.count('PROPN')\n",
        "\n",
        "# NOUN\n",
        "def nouns(text, model=nlp):\n",
        "  doc= nlp(text)\n",
        "  pos= [token.pos_ for token in doc]\n",
        "  return pos.count('NOUN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_CnyVvYmnnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create two columns, witht the number of nouns and proper nouns\n",
        "reviews['num_propn'] = reviews['review_comment_message'].apply(proper_nouns)\n",
        "reviews['num_noun'] = reviews['review_comment_message'].apply(nouns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yhLoWcUm7_Y",
        "colab_type": "code",
        "outputId": "cc1d8b34-c024-4ee6-9cae-48f21020b46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# computing the mean of proper nouns\n",
        "good_propn= reviews[reviews['is_good_review']== 1]['num_propn'].mean()\n",
        "bad_propn= reviews[reviews['is_good_review']== 0]['num_propn'].mean()\n",
        "\n",
        "# computing the mean of nouns\n",
        "good_noun= reviews[reviews['is_good_review']== 1]['num_noun'].mean()\n",
        "bad_noun= reviews[reviews['is_good_review']== 0]['num_noun'].mean()\n",
        "\n",
        "# print results to compare\n",
        "print(\"Mean number of proper nouns for good and bad reviews are %.2f and %.2f respectively\"%(good_propn, bad_propn))\n",
        "print(\"Mean number of nouns for good and bad reviews are %.2f and %.2f respectively\"%(good_noun, bad_noun))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean number of proper nouns for good and bad reviews are 0.48 and 0.88 respectively\n",
            "Mean number of nouns for good and bad reviews are 2.10 and 3.63 respectively\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX3gXTlJpfgy",
        "colab_type": "text"
      },
      "source": [
        "Named Entity Recognition\n",
        "\n",
        "It classifies named entities into predefined categories, like person, organization, country, etc.\n",
        "\n",
        "Uses:\n",
        "- Efficient search algorithms\n",
        "- Question answering\n",
        "- News article classification\n",
        "- Customer service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGBKCEYcwD-X",
        "colab_type": "code",
        "outputId": "6023b772-9485-4192-cda1-f4dc6d05b42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Let's practice NER\n",
        "nlp= spacy.load('pt_core_news_sm')\n",
        "text= reviews['review_comment_message'][11]\n",
        "doc= nlp(text)\n",
        "\n",
        "# print all named entities:\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comprei PER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEFxF-z41bvu",
        "colab_type": "text"
      },
      "source": [
        "To find person's names, we can use the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez6Jv9BVAiHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_persons(text, model=nlp):\n",
        "  doc= model(text)\n",
        "  persons= [ent.text for ent in doc.ents if ent.label_== 'PERSON']\n",
        "  return persons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quSVEyXZBQA0",
        "colab_type": "text"
      },
      "source": [
        "Vectorization\n",
        "\n",
        "The process of converting text into vectors, so it can be used in ML\n",
        "\n",
        "Bag of Words is a model that do vectorization. It's important to perform text preprocessing as it leads to smaller vocabularies, and reducing the number of dimensions helps improve performance.\n",
        "\n",
        "CountVectorizer, from scikit-learn, is the tool used to perform bag of words.\n",
        "It needs some arguuments to pre-processing text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH_3jbeFDYhm",
        "colab_type": "code",
        "outputId": "14a423a2-7e8d-4ea7-d151-c272b906b9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create CountVectorizer object, specifying the arguments to preprocess text\n",
        "stop_words_port= spacy.lang.pt.stop_words.STOP_WORDS\n",
        "vectorizer= CountVectorizer(stop_words=stop_words_port)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test= train_test_split(reviews['review_comment_message'], reviews['is_good_review'], test_size=0.25, random_state=24)\n",
        "\n",
        "# Generate training Bow vectors\n",
        "X_train_bow= vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Generate test Bow vector\n",
        "X_test_bow= vectorizer.transform(X_test) \n",
        "\n",
        "print(X_train_bow.shape)\n",
        "print(X_test_bow.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31315, 13603)\n",
            "(10439, 13603)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc1LdpyTvteF",
        "colab_type": "text"
      },
      "source": [
        "We will try the Naive Bayes classifier to this problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-m9DPtGv5vH",
        "colab_type": "code",
        "outputId": "c867ba4c-a4e7-4b6a-9cd3-2774d59fafd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Import multinomialNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# create MultinomialNB object\n",
        "clf= MultinomialNB()\n",
        "\n",
        "# Train clf\n",
        "clf.fit(X_train_bow, y_train)\n",
        "\n",
        "# Compute accuracy on test set\n",
        "accuracy= clf.score(X_test_bow, y_test)\n",
        "\n",
        "print(\"The accuracy of the classifier is %.3f\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the classifier is 0.866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXKQQpMSPu2",
        "colab_type": "code",
        "outputId": "a30b3fee-85bb-4132-a7f4-171399f3f76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Predict the sentiment of a negative review\n",
        "review= \"detestei o produto, nao gostei do vendedor, estou insatisfeito\"\n",
        "\n",
        "prediction= clf.predict(vectorizer.transform([review]))[0]\n",
        "\n",
        "print(\"The sentiment predicted by the classifier is %i\" % prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment predicted by the classifier is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2EV8OM8SexR",
        "colab_type": "text"
      },
      "source": [
        "On the example above, the model correct classified a bad review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JAAja-2m6pd",
        "colab_type": "text"
      },
      "source": [
        "Techniques to give context to a review\n",
        "\n",
        "n-grams\n",
        "\n",
        "It is a contiguous sequence of n-elements, or words, in a given document. A bag of words is n-gram model where n= 1.\n",
        "\n",
        "Example: \"I love you\". If n=1, we have:\n",
        "- \"I\"\n",
        "- \"Love\"\n",
        "- \"You\"\n",
        "\n",
        "If we change n to 2, we would have:\n",
        "- \"I love\"\n",
        "- \"love you\"\n",
        "\n",
        "It helps the model to undestand the relationship between the words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfYH18VYWanO",
        "colab_type": "code",
        "outputId": "b5702e82-b91f-4ad3-a7ab-4fc8a44d127b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# To avoid the curse of dimensionality, don't use more than n=3\n",
        "# We are going to compare how much it increases when we increase the n-gram\n",
        "\n",
        "vectorizer_ng1 = CountVectorizer(ngram_range=(1, 1))\n",
        "ng1 = vectorizer_ng1.fit_transform(X_train)\n",
        "\n",
        "vectorizer_ng2 = CountVectorizer(ngram_range=(1, 2))\n",
        "ng2 = vectorizer_ng2.fit_transform(X_train)\n",
        "\n",
        "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
        "ng3 = vectorizer_ng3.fit_transform(X_train)\n",
        "\n",
        "print(\"number of features by n-grams is:\\n ng1= %i \\n ng2= %i \\n ng3= %i\" % (ng1.shape[1], ng2.shape[1], ng3.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of features by n-grams is:\n",
            " ng1= 13963 \n",
            " ng2= 114172 \n",
            " ng3= 295810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWRvrBNY2SS",
        "colab_type": "text"
      },
      "source": [
        "We can see that with n=1 we have 13k features, while with n=3 it increases to 295k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zlv15guW-sE",
        "colab_type": "code",
        "outputId": "001c62fb-3ad1-4d16-fe72-5eb227449ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# We will try the same model again, now with n-gram= 2\n",
        "\n",
        "vectorizer_ng= CountVectorizer(stop_words=stop_words_port, ngram_range=(1,3))\n",
        "\n",
        "X_train_bow_ng= vectorizer_ng.fit_transform(X_train)\n",
        "X_test_bow_ng= vectorizer_ng.transform(X_test) \n",
        "\n",
        "clf.fit(X_train_bow_ng, y_train)\n",
        "\n",
        "accuracy_ng= clf.score(X_test_bow_ng, y_test)\n",
        "\n",
        "print(\"The accuracy of the classifier is %.3f\" % accuracy_ng)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the classifier is 0.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9wH0cslXw9q",
        "colab_type": "text"
      },
      "source": [
        "Term Frenquency - Inverse Document Frequency -  **TF-IDF**\n",
        "\n",
        "The idea is, more frequent the word is accross all documents, plus the number of times it occurs, more weight it should have. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwCg--uDXzi7",
        "colab_type": "code",
        "outputId": "71ca57ff-3e3f-41cc-afdb-7498b6df464a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# instead using CountVectorizer(), we will use TfadVectorizer() from scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer= TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix= vectorizer.fit_transform(X_train)\n",
        "\n",
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31315, 13963)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtasV4TMDjNN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Cosine similarity \n",
        "\n",
        "It is the cosine distance between two vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-aIN0hUF0-G",
        "colab_type": "code",
        "outputId": "8b95a575-0e6c-4765-e586-59cb32d8b75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "# record time\n",
        "start= time.time()\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim= cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# print the cosine similarity matrix\n",
        "print(cosine_sim)\n",
        "\n",
        "# Print time taken\n",
        "print(\"Time taken: %s seconds\" %(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.         0.20017999 ... 0.         0.         0.11678042]\n",
            " [0.         1.         0.         ... 0.         0.04735246 0.        ]\n",
            " [0.20017999 0.         1.         ... 0.         0.         0.58337711]\n",
            " ...\n",
            " [0.         0.         0.         ... 1.         0.         0.        ]\n",
            " [0.         0.04735246 0.         ... 0.         1.         0.        ]\n",
            " [0.11678042 0.         0.58337711 ... 0.         0.         1.        ]]\n",
            "Time taken: 18.618732452392578 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LnAsRGzLVgG",
        "colab_type": "code",
        "outputId": "bf6da3fd-d891-432f-ee42-301434689e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "# we can use linear_kernal to calculate cosine similarity. It takes less time to process and it produces the same result.\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import time\n",
        "# record time\n",
        "start= time.time()\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim= linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# print the cosine similarity matrix\n",
        "print(cosine_sim)\n",
        "\n",
        "# Print time taken\n",
        "print(\"Time taken: %s seconds\" %(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.         0.20017999 ... 0.         0.         0.11678042]\n",
            " [0.         1.         0.         ... 0.         0.04735246 0.        ]\n",
            " [0.20017999 0.         1.         ... 0.         0.         0.58337711]\n",
            " ...\n",
            " [0.         0.         0.         ... 1.         0.         0.        ]\n",
            " [0.         0.04735246 0.         ... 0.         1.         0.        ]\n",
            " [0.11678042 0.         0.58337711 ... 0.         0.         1.        ]]\n",
            "Time taken: 19.20054602622986 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3SqmC8xai_j",
        "colab_type": "text"
      },
      "source": [
        "Word embeddings\n",
        "To find similarity between words or sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AST7VrbIdLtN",
        "colab_type": "code",
        "outputId": "f85cf3ad-ebfa-48f6-f449-4073e4e8b268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "reviews['review_comment_message'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                Recebi bem antes do prazo estipulado.\n",
              "1    Parabéns lojas lannister adorei comprar pela I...\n",
              "2    aparelho eficiente. no site a marca do aparelh...\n",
              "3        Mas um pouco ,travando...pelo valor ta Boa.\\n\n",
              "4    Vendedor confiável, produto ok e entrega antes...\n",
              "Name: review_comment_message, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynh9fl8xdVRD",
        "colab_type": "code",
        "outputId": "dd2c2629-84d6-44ad-ede7-6bcdcc42d55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# let's check how similar are the reviews\n",
        "\n",
        "# first, creat a Doc\n",
        "review_1_doc= nlp(reviews['review_comment_message'][1])\n",
        "review_2_doc= nlp(reviews['review_comment_message'][2])\n",
        "review_3_doc= nlp(reviews['review_comment_message'][3])\n",
        "\n",
        "# Now, use the function similarity\n",
        "print(review_1_doc.similarity(review_2_doc))\n",
        "print(review_2_doc.similarity(review_3_doc))\n",
        "print(review_3_doc.similarity(review_1_doc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.06718104243836638\n",
            "0.26803800927046\n",
            "0.23318636637941698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A7VuI6YeFHS",
        "colab_type": "code",
        "outputId": "e5420ca7-bd9f-484e-d42c-bbde98598ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# trying Multinomial Naive Bayes with Tfidf vectorization\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import time\n",
        "\n",
        "# Create CountVectorizer object, specifying the arguments to preprocess text\n",
        "stop_words_port= spacy.lang.pt.stop_words.STOP_WORDS\n",
        "vectorizer= TfidfVectorizer(stop_words=stop_words_port)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test= train_test_split(reviews['review_comment_message'], reviews['is_good_review'], test_size=0.25, random_state=24)\n",
        "\n",
        "start= time.time()\n",
        "\n",
        "# Generate training Bow vectors\n",
        "X_train_vec= vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Generate test Bow vector\n",
        "X_test_vec= vectorizer.transform(X_test) \n",
        "\n",
        "# create MultinomialNB object\n",
        "clf= MultinomialNB()\n",
        "\n",
        "# Train clf\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# Compute accuracy on test set\n",
        "accuracy= clf.score(X_test_vec, y_test)\n",
        "\n",
        "print(\"The accuracy of the classifier is %.3f\" % accuracy)\n",
        "print(\"Time taken: %s seconds\" %(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the classifier is 0.866\n",
            "Time taken: 0.5172257423400879 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSGA_y7Wk9KK",
        "colab_type": "code",
        "outputId": "d38749fd-afed-43e7-837e-93583a7dd13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "clf_y_pred = clf.predict(X_test_vec)\n",
        "print(metrics.classification_report(y_test, clf_y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.77      0.81      3757\n",
            "           1       0.88      0.92      0.90      6682\n",
            "\n",
            "    accuracy                           0.87     10439\n",
            "   macro avg       0.86      0.85      0.85     10439\n",
            "weighted avg       0.87      0.87      0.86     10439\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s-HRKptmtvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}